<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">

<html xmlns="http://www.w3.org/1999/xhtml"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
    <title>CS180 Project 1</title>
    <link rel="StyleSheet" href="./main.css" type="text/css" media="all">
  </head>
  <body>
    <h1>
      CS180 Project 2
    </h1>
    <h1>
      Results
    
      <h2>
        <a>1.1: Finite Difference Operator</a>
        <h3>
          <a>Original</a>

          <img src="./images/all/cameraman.png" height="542" width="540">
        </h3>
        <h3>
          <a>Convolution with Finite Difference in the x direction</a>

          <img src="./images/1.1/partial_x.png" height="542" width="540">
        </h3>
        <h3>
          <a>Convolution with Finite Difference in the y direction</a>
          <img src="./images/1.1/partial_y.png" height="542" width="540">
        </h3>
        <h3>
          <a>Gradient Magnitude Image </a>
          <img src="./images/all/1.1/gradient.png" height="542" width="540">
        </h3>
        <h3>
          <a>Binarized Edge Image (treshold = 0.3)</a>
          <img src="./images/all/1.1/edge_gradient.png" height="542" width="540">
        </h3>
      </h2>

      <h2>
        <a>1.2: Derivative of Gaussian Filter</a>
        <h3>
          <a>Convolution with Gaussian Kernel (Blurred Image)</a>
          <img src="./images/all/1.2/blurred_camera.png" height="542" width="650">
        </h3>
        <h3>
          <a>Convolution of Blurred Image with D_x</a>
          <img src="./images/all/1.2/blurred_x_partial_camera.png" height="542" width="650">
        </h3>
        <h3>
          <a>Convolution of Blurred Image with D_y</a>
          <img src="./images/all/1.2/blurred_y_partial_camera.png" height="542" width="650">
        </h3>
        <h3>
          <a>Blurred Gradient Magnitude</a>
          <img src="./images/all/1.2/gradient_blurred_Gaussian.png" height="540" width="542">
        </h3>
        <h3>
          <a>Binarized Edge Image (treshold = 0.07) </a>
          <img src="./images/all/1.2/edge_gradient_blurred_Gaussian.png" height="540" width="542">
        </h3>
        Note above that the edge image on the blurred image is much less noisy than before.
        Additionally, the edges are typically thicker and have fewer discontinuities than when using the difference filter on the original iamge.

        
        <h3>
          <a>Original Gaussian Filter</a>
          <img src="./images/all/1.2/2D Gaussian Filter.png" height="480" width="640">
        </h3>
        
        <h3>
          <a>Gaussian Convolved with D_x</a>
          <img src="./images/all/1.2/DoG_x.png" height="480" width="640">
        </h3>
        <h3>
          <a>Gaussian Convolved with D_y</a>
          <img src="./images/all/1.2/DoG_y.png" height="480" width="640">
        </h3>
        <h3>
          <a>Blurred Gradient Magnitute from DoG</a>
          <img src="./images/all/1.2/gradient_blurred_DoG.png" height="540" width="542">
        </h3>
        <h3>
          <a>Binarized Edge Image (treshold = 0.07)</a>
          <img src="./images/all/1.2/edge_gradient_blurred_DoG.png" height="540" width="542">
        </h3>
        Here the results of convolving twice (first with the Gaussian and then the D_x/D_y) filters are the same as the results of convolving with the combined filter.
      </h2>
      <h2>
        <a>2.1: Image "Sharpening"</a>
      </h2>
        <h3>
          <a>Taj Mahal</a>
          <h4> 
          Original
          <img src="./images/all/2.1/castle.jpeg" height="853" width="853">
          Blurred
          <img src="./images/2.1/blurred_castle.png" height="853" width="853">
          Sharpened
          <img src="./images/2.1/sharpened_castle.png" height="853" width="853">
          </h4>
        </h3>
        <h3>
          <a>Bird</a>
          <h4> 
          Original
          <img src="./images/all/2.1/bird.jpg" height="850" width="1280">
          Blurred
          <img src="./images/2.1/blurred_bird.png" height="850" width="1280">
          Sharpened
          <img src="./images/2.1/sharpened_bird.png" height="850" width="1280">
          </h4> 
        </h3>
        <h3>
          <h4> 
          <a>Boats</a>
          Original
          <img src="./images/all/2.1/folkstone.jpg" height="853" width="1280">
          Blurred
          <img src="./images/2.1/blurred_folkstone.png" height="850" width="1280">
          Sharpened
          <img src="./images/2.1/sharpened_folkstone.png" height="850" width="1280">
          </h4> 
        </h3>
        <h3>
          <a>Blurring and unblurring a sharp image</a>
        </h3>
    
        <h3>
          
          <a>Discussion: </a>
          The unsharp mask filter made the image appear sharper overall. The dark lines on the orginal images were emphasized, which makes the image
          more visually striking.
          But sharpening the blurred image does not recover the original image perfectly, possibly due to the loss of high 
          frequencies during the blurring process. 
        </h3>
      <h2>
        <a>2.2: Hybrid Images</a>
        <h3>
          <a>Derek/Nutmeg</a>
          <img src="./images/all/DerekPicture.jpg" height="700" width="500">
          <img src="./images/all/nutmeg.jpg" height="550" width="733">
          <img src="./images/all/2.2/hybrid_bw.png" height="600" width="800">
        </h3>


        <h3>
          <a>Tiger/Dog</a>
          <img src="./images/all/tiger.jpg" height="750" width="500">
          <img src="./images/all/dog.jpg" height="400" width="615">
          <img src="./images/all/2.2/Tiger_Dog_bw.png" height="600" width="760">
        </h3>


28      <a>Boy/Owl</a>
          <img src="./images/all/boy.jpg" height="500" width="690">
          <img src="./images/all/owl.jpg" height="400" width="715">
          <img src="./images/all/2.2/Owl_Boy_bw.png" height="600" width="760">
        </h3>

    
        <h3>
          <a>Log magnitudes of FFTs of an image of a boy</a>
          <img src="./images/2.2/FFT of Image boy.png" height="480" width="640">
        </h3>
        <h3>
          <a>Low pass filtered version</a>
          <img src="./images/2.2/FFT of Image boy lowpass.png" height="480" width="640">
        </h3>
        <h3>
          <a>Log magnitudes of FFTs of an image of an owl</a>
          <img src="./images/2.2/FFT of Image owl.png" height="480" width="640">
        </h3>
        <h3>
          <a>High pass filtered version</a>
          <img src="./images/2.2/FFT of Image owl highpass.png" height="480" width="640">
        </h3>
        <h3>
          <a>Sum of the above low pass filtered and high pass filtered version</a>
          <img src="./images/2.2/FFT of Hybrid Image.png" height="480" width="640">
        </h3>
        <h3>
          <a>Hybrid Image</a>
          <img src="./images/2.2/Owl_Boy_bw.png" height="480" width="640">

          <h3>
          
            <a>Discussion: </a>
            The boy and Owl image is my favorite. The two subjects here share similar facial structures, which makes
            alignment easy. Also, the owl has  complex feather structures, which is well perserved in 
            high frequency.
          </h3>


        </h3>
        <h3>
          <a>Failure</a>
          <img src="./images/all/small.jpg" height="750" width="500">
          <img src="./images/all/road.png" height="400" width="615">
          <img src="./images/all/2.2/mistake_bw.png" height="480" width="640">
        </h3>
        <a>Discussion: </a>
            This is an example of failure. The subjects of the two images here don't align, which means that when you tries to decipher 
            the low frequency image, the high frequency one will distract you negatively. 
        <h3>





      </h2>
      <h2>
        <a>2.3: Gaussian and Laplacian Stacks</a>
        <h3>
          <a>Apple Half</a>
          <img src="./images/all/2.3/half1 Level 0.png" height="200" width="260">
          <img src="./images/all/2.3/half1 Level 1.png" height="200" width="260">
          <img src="./images/all/2.3/half1 Level 2.png" height="200" width="260">
          <img src="./images/all/2.3/half1 Level 3.png" height="200" width="260">
          <img src="./images/all/2.3/half1 Level 4.png" height="200" width="260">
        </h3>

        <h3>
          <a>Orange Half</a>
          <img src="./images/all/2.3/half2 Level 0.png" height="200" width="260">
          <img src="./images/all/2.3/half2 Level 1.png" height="200" width="260">
          <img src="./images/all/2.3/half2 Level 2.png" height="200" width="260">
          <img src="./images/all/2.3/half2 Level 3.png" height="200" width="260">
          <img src="./images/all/2.3/half2 Level 4.png" height="200" width="260">
        </h3>
          <a>Combined!</a>
        <img src="./images/all/2.3/imgout Level 0.png" height="200" width="260">
        <img src="./images/all/2.3/imgout Level 1.png" height="200" width="260">
        <img src="./images/all/2.3/imgout Level 2.png" height="200" width="260">
        <img src="./images/all/2.3/imgout Level 3.png" height="200" width="260">
        <img src="./images/all/2.3/imgout Level 4.png" height="200" width="260">
        </h3>

        <h3>
          <a>Final result</a>
          <img src="./images/all/2.3/final_im.png" height="480" width="640">
        </h3>

      </h2>
      <h2>
        <a>2.4: Multiresolution Blending</a>
      </h2>
        <h3>
          <a>Vertical seam</a>
          <img src="./images/all/cat1.jpg" height="640" width="480">
          <img src="./images/all/cat2.jpg" height="640" width="480">
          <img src="./images/all/2.4/cat1+2.png" height="480" width="640">
        </h3>
        <h3>
          <a>Irregular mask</a>
          <img src="./images/all/bridge.jpeg" height="640" width="480">
          <img src="./images/all/view.jpeg" height="420" width="720">
          <img src="./images/all/bridge_view.png" height="480" width="640">
        </h3>
        <h3>
          <a>Laplacian Stack</a>
          <img src="./images/all/2.4/bridge Level 0.png" height="640" width="480">
          <img src="./images/all/2.4/bridge Level 1.png" height="640" width="480">
          <img src="./images/all/2.4/bridge Level 2.png" height="640" width="480">
          <img src="./images/all/2.4/bridge Level 4.png" height="640" width="480">

          <img src="./images/all/view.jpeg" height="420" width="720">



          
          <img src="./images/all/bridge_view.png" height="480" width="640">
          <img src="./images/all/bridge.jpeg" height="640" width="480">
          <img src="./images/all/view.jpeg" height="420" width="720">
          <img src="./images/all/bridge_view.png" height="480" width="640">
          <img src="./images/all/bridge.jpeg" height="640" width="480">
          <img src="./images/all/view.jpeg" height="420" width="720">
          <img src="./images/all/bridge_view.png" height="480" width="640">
          <img src="./images/all/bridge.jpeg" height="640" width="480">
          <img src="./images/all/view.jpeg" height="420" width="720">
          <img src="./images/all/bridge_view.png" height="480" width="640">
        </h3>
    </h1>

    <h1>
      Reflections
    </h1>
    <p>
    Discussion here.
    </p>
    <p>
      In order to achieve this, I mostly followed the methods suggested in the project page, which worked mostly without complication.
      Specifically, I implemented a search over all offsets to align the green and red images to the blue image.
      8 percent of the borders of the images are removed to avoid the dark borders causing trouble with the alignment metric.
      The quality of the offset is judged by the sum of squared differences in pixels, also as suggested.
    </p>
    <p>
      Some problems I ran into in the course of developing these results include:
      <ul>
      <li>For a long time I thought I had a bug where the wrong image was being moved when just trying to align the green image to the blue, causing me to question my sanity.
      This was actually because I was misinterpreting the image I was using for debugging: areas which are black on the green image would look blue, because of course the green-value was zero and the blue-value was nonzero.</li>
      <li>The alignment, even for low-res images, will not work if the borders are not cropped.</li>
      <li>For the emir picture in particular, the fact that his jacket is blue means that the l2 metric actually
        isn't very good for aligning the red image to the blue image, since the blue values are high and the red values are low.
        Originally, this resulted in complete failure when the image was cropped to the middle third in both dimensions.
        This was resolved by reducing the extent of the cropping to just 8% of the image dimension per side, so that the L2 norm could be applied to other areas of the image.
        Of course, this is not a fully general solution, and the emir photo still has clearly the worst alignment of the ones in this set.
        In general it would probably be better to use an edge detector or a combination of metrics.
      </li>
      <li>Naturally, the initial for-loop implementation of the L2 difference is way too slow to be useful. Replacing it with a numpy call made things something like 50-200 times faster, which was good enough.</li>
      <li>It's technically only necessary to search a 3 pixel range in the intermediate calls of the pyramid search to find the best alignment, assuming the "greedy" solution is best.
        However, there was some concern that the greediness assumption wouldn't hold, so I increased the range to 7 pixels just in case.
      </li>
      </ul>
    </p>
    <p>As a subjective matter, I think (aside from removing the colored borders), the biggest problem with the colorized images is the color balance. Some of the images, particularly the ones with sky or water, look either kind of washed out or gray. As mentioned on the website, it might be good to try and decompose the current (R, G, B) as a combination of some other (R', G', and B'). But it's not clear how to do this without obsessively trying a bunch of combinations manually.</p>

</body></html>
